{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure python 3 compatibility:\n",
    "from __future__ import division, print_function, absolute_import, unicode_literals\n",
    "\n",
    "# The package for accessing files in directories, etc.:\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Warning package in case something goes wrong\n",
    "from warnings import warn\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "\n",
    "def install(package):\n",
    "    subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "# Package for downloading online files:\n",
    "try:\n",
    "    # This package is not part of anaconda and may need to be installed.\n",
    "    import wget\n",
    "except ImportError:\n",
    "    warn('wget not found.  Will install with pip.')\n",
    "    import pip\n",
    "    install(wget)\n",
    "    import wget\n",
    "\n",
    "# The mathematical computation package:\n",
    "import numpy as np\n",
    "\n",
    "# The package used for creating and manipulating HDF5 files:\n",
    "import h5py\n",
    "\n",
    "# Packages for plotting:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Finally import pyUSID:\n",
    "try:\n",
    "    import pyUSID as usid\n",
    "except ImportError:\n",
    "    warn('pyUSID not found.  Will install with pip.')\n",
    "    import pip\n",
    "    install('pyUSID')\n",
    "    import pyUSID as usid\n",
    "    \n",
    "import pycroscopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the compressed data file from Github:\n",
    "url = 'https://raw.githubusercontent.com/pycroscopy/pyUSID/master/data/STS.zip'\n",
    "zip_path = 'STS.zip'\n",
    "if os.path.exists(zip_path):\n",
    "    os.remove(zip_path)\n",
    "_ = wget.download(url, zip_path, bar=None)\n",
    "\n",
    "zip_path = os.path.abspath(zip_path)\n",
    "# figure out the folder to unzip the zip file to\n",
    "folder_path, _ = os.path.split(zip_path)\n",
    "zip_ref = zipfile.ZipFile(zip_path, 'r')\n",
    "# unzip the file\n",
    "zip_ref.extractall(folder_path)\n",
    "zip_ref.close()\n",
    "# delete the zip file\n",
    "os.remove(zip_path)\n",
    "\n",
    "data_file_path = 'STS.asc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# File Format = ASCII\n",
      "\n",
      "# Created by SPIP 4.6.5.0 2016-09-22 13:32\n",
      "\n",
      "# Original file: C:\\Users\\Administrator\\AppData\\Roaming\\Omicron NanoTechnology\\MATRIX\\default\\Results\\16-Sep-2016\\I(V) TraceUp Tue Sep 20 09.17.08 2016 [14-1]  STM_Spectroscopy STM\n",
      "\n",
      "# x-pixels = 100\n",
      "\n",
      "# y-pixels = 100\n",
      "\n",
      "# x-length = 29.7595\n",
      "\n",
      "# y-length = 29.7595\n",
      "\n",
      "# x-offset = -967.807\n",
      "\n",
      "# y-offset = -781.441\n",
      "\n",
      "# z-points = 500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(data_file_path, 'r') as file_handle:\n",
    "    for lin_ind in range(10):\n",
    "        print(file_handle.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the raw data into memory\n",
    "file_handle = open(data_file_path, 'r')\n",
    "string_lines = file_handle.readlines()\n",
    "file_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-pixels :\t 100\n",
      "y-pixels :\t 100\n",
      "x-length :\t 29.7595\n",
      "y-length :\t 29.7595\n",
      "x-offset :\t -967.807\n",
      "y-offset :\t -781.441\n",
      "z-points :\t 500\n",
      "z-section :\t 491\n",
      "z-unit :\t nV\n",
      "z-range :\t 2000000000\n",
      "z-offset :\t 1116.49\n",
      "value-unit :\t nA\n",
      "scanspeed :\t 59519000000\n",
      "voidpixels :\t 0\n"
     ]
    }
   ],
   "source": [
    "# Reading parameters stored in the first few rows of the file\n",
    "parm_dict = dict()\n",
    "for line in string_lines[3:17]:\n",
    "    line = line.replace('# ', '')\n",
    "    line = line.replace('\\n', '')\n",
    "    temp = line.split('=')\n",
    "    test = temp[1].strip()\n",
    "    try:\n",
    "        test = float(test)\n",
    "        # convert those values that should be integers:\n",
    "        if test % 1 == 0:\n",
    "            test = int(test)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    parm_dict[temp[0].strip()] = test\n",
    "\n",
    "# Print out the parameters extracted\n",
    "for key in parm_dict.keys():\n",
    "    print(key, ':\\t', parm_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = int(parm_dict['y-pixels'])\n",
    "num_cols = int(parm_dict['x-pixels'])\n",
    "num_pos = num_rows * num_cols\n",
    "spectra_length = int(parm_dict['z-points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_headers = len(string_lines) - num_pos\n",
    "num_headers = 403\n",
    "\n",
    "# Extract the STS data from subsequent lines\n",
    "raw_data_2d = np.zeros(shape=(num_pos, spectra_length), dtype=np.float32)\n",
    "for line_ind in range(num_pos):\n",
    "    this_line = string_lines[num_headers + line_ind]\n",
    "    string_spectrum = this_line.split('\\t')[:-1]  # omitting the new line\n",
    "    raw_data_2d[line_ind] = np.array(string_spectrum, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_v = 1  # This is the one parameter we are not sure about\n",
    "\n",
    "folder_path, file_name = os.path.split(data_file_path)\n",
    "file_name = file_name[:-4] + '_'\n",
    "\n",
    "# Generate the x / voltage / spectroscopic axis:\n",
    "volt_vec = np.linspace(-1 * max_v, 1 * max_v, spectra_length)\n",
    "\n",
    "h5_path = os.path.join(folder_path, file_name + '.h5')\n",
    "\n",
    "sci_data_type = '4DSTEM'\n",
    "quantity = 'Intensity'\n",
    "units = 'Counts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dims = [usid.write_utils.Dimension('X', 'a. u.', parm_dict['x-pixels']),\n",
    "            usid.write_utils.Dimension('Y', 'a. u.', parm_dict['y-pixels'])]\n",
    "spec_dims = usid.write_utils.Dimension('Bias', 'V', volt_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_file = pycroscopy.io.BEodfTranslator('/srv/home/chenyu/DEbackup/091618/S2/npy/S2_00000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_file = pycroscopy.io.PtychographyTranslator(h5_file,'/srv/home/chenyu/DEbackup/091618/Test.h5',\n",
    "                                               '/srv/home/chenyu/DEbackup/091618/S2/npy/',\n",
    "                                              bin_factor=None, bin_func=np.mean,\n",
    "                                              start_image = 0, scan_size_x = 150, scan_size_y = 150, image_type = 'tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Built-in numptranslator requires all images to be loaded into memory to process, which is not good for 4DSTEM data as they are too big.\n",
    "<br>-Ptychography translator can be used, but it currently only supports dm3 and tif stack, need to be modified to be applied on npy/mat data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Translater part defination in ptychography.py inside pycroscopy\n",
    "These translators can be accessed via pycroscopy.io.translators or pycroscopy.translators\n",
    "\n",
    "    def translate(self, h5_path, image_path, bin_factor=None, bin_func=np.mean, start_image=0, scan_size_x=None,\n",
    "                  scan_size_y=None, image_type='.tif'):\n",
    "        \"\"\"\n",
    "        Basic method that adds Ptychography data to existing hdf5 thisfile\n",
    "        You must have already done the basic translation with BEodfTranslator\n",
    "        \n",
    "        Parameters\n",
    "        ----------------\n",
    "        h5_path : str\n",
    "            Absolute path to where the HDF5 file should be located\n",
    "        image_path : str\n",
    "            Absolute path to folder holding the image files\n",
    "        bin_factor : array_like of uint, optional\n",
    "            Downsampling factor for each dimension.  Default is None.\n",
    "        bin_func : callable, optional\n",
    "            Function which will be called to calculate the return value\n",
    "            of each block.  Function must implement an axis parameter,\n",
    "            i.e. numpy.mean.  Ignored if bin_factor is None.  Default is\n",
    "            numpy.mean.\n",
    "        start_image : int, optional\n",
    "            Integer denoting which image in the file path should be considered the starting\n",
    "            point.  Default is 0, start with the first image on the list.\n",
    "        scan_size_x : int, optional\n",
    "            Number of Ronchigrams in the x direction.  Default is None, value will be determined\n",
    "            from the number of images and `scan_size_y` if it is given.\n",
    "        scan_size_y : int, optional\n",
    "            Number of Ronchigrams in the y direction.  Default is None, value will be determined\n",
    "            from the number of images and `scan_size_x` if it is given.\n",
    "        image_type : str\n",
    "            File extension of images to be read.  Default '.tif'\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        h5_main : h5py.Dataset\n",
    "            HDF5 Dataset object that contains the flattened images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
